{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e588d30-7653-4ed2-b465-167792d6e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nitro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nitro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Nitro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Nitro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a015560-fa36-4eca-bc8c-d3e4330d0dc6",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8de5f3-4794-40c5-98b6-051c59c0ecb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_as_int</th>\n",
       "      <th>answer_as_int</th>\n",
       "      <th>question_len</th>\n",
       "      <th>answer_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>[54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...</td>\n",
       "      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n",
       "      <td>71</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n",
       "      <td>[46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...</td>\n",
       "      <td>55</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "      <td>[56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...</td>\n",
       "      <td>[37, 77, 80, 69, 67, 82, 1, 71, 82, 14]</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "      <td>[45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...</td>\n",
       "      <td>[34, 63, 75, 67, 80, 77, 76, 14]</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "      <td>[38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...</td>\n",
       "      <td>[43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>221608</td>\n",
       "      <td>Well that one. The one who keeps looking at me.</td>\n",
       "      <td>ft could be you flatter yourself CoghilL It's ...</td>\n",
       "      <td>[54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...</td>\n",
       "      <td>[68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>221609</td>\n",
       "      <td>Choose your targets men. That's right Watch th...</td>\n",
       "      <td>Keep steady. You're the best shots of the Twen...</td>\n",
       "      <td>[34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...</td>\n",
       "      <td>[42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...</td>\n",
       "      <td>61</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>221610</td>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "      <td>[34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...</td>\n",
       "      <td>[38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139407</th>\n",
       "      <td>221611</td>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>[56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...</td>\n",
       "      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>221612</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n",
       "      <td>[43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139409 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           question  \\\n",
       "0                1  Well, I thought we'd start with pronunciation,...   \n",
       "1                2  Not the hacking and gagging and spitting part....   \n",
       "2                3  You're asking me out.  That's so cute. What's ...   \n",
       "3                4  No, no, it's my fault -- we didn't have a prop...   \n",
       "4                9     Gosh, if only we could find Kat a boyfriend...   \n",
       "...            ...                                                ...   \n",
       "139404      221608    Well that one. The one who keeps looking at me.   \n",
       "139405      221609  Choose your targets men. That's right Watch th...   \n",
       "139406      221610  Colonel Durnford... William Vereker. I hear yo...   \n",
       "139407      221611                           Your orders, Mr Vereker?   \n",
       "139408      221612  I'm to take the Sikali with the main column to...   \n",
       "\n",
       "                                                   answer  \\\n",
       "0       Not the hacking and gagging and spitting part....   \n",
       "1       Okay... then how 'bout we try out some French ...   \n",
       "2                                              Forget it.   \n",
       "3                                                Cameron.   \n",
       "4                               Let me see what I can do.   \n",
       "...                                                   ...   \n",
       "139404  ft could be you flatter yourself CoghilL It's ...   \n",
       "139405  Keep steady. You're the best shots of the Twen...   \n",
       "139406  Good ones, yes, Mr Vereker. Gentlemen who can ...   \n",
       "139407  I'm to take the Sikali with the main column to...   \n",
       "139408  Lord Chelmsford seems to want me to stay back ...   \n",
       "\n",
       "                                          question_as_int  \\\n",
       "0       [54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...   \n",
       "1       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...   \n",
       "2       [56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...   \n",
       "3       [45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...   \n",
       "4       [38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...   \n",
       "...                                                   ...   \n",
       "139404  [54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...   \n",
       "139405  [34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...   \n",
       "139406  [34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...   \n",
       "139407  [56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...   \n",
       "139408  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...   \n",
       "\n",
       "                                            answer_as_int  question_len  \\\n",
       "0       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...            71   \n",
       "1       [46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...            55   \n",
       "2                 [37, 77, 80, 69, 67, 82, 1, 71, 82, 14]            62   \n",
       "3                        [34, 63, 75, 67, 80, 77, 76, 14]            65   \n",
       "4       [43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...            46   \n",
       "...                                                   ...           ...   \n",
       "139404  [68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...            47   \n",
       "139405  [42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...            61   \n",
       "139406  [38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...            74   \n",
       "139407  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...            24   \n",
       "139408  [43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...            56   \n",
       "\n",
       "        answer_len  \n",
       "0               55  \n",
       "1               73  \n",
       "2               10  \n",
       "3                8  \n",
       "4               25  \n",
       "...            ...  \n",
       "139404          59  \n",
       "139405          85  \n",
       "139406          60  \n",
       "139407          56  \n",
       "139408          62  \n",
       "\n",
       "[139409 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"dialogs_expanded.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd95cc-47f2-4fb4-829d-c598a43c5498",
   "metadata": {},
   "source": [
    "## Select Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d976ff7-d911-489c-80d3-9116975bf6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "      <td>Cameron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gosh, if only we could find Kat a boyfriend...</td>\n",
       "      <td>Let me see what I can do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>Well that one. The one who keeps looking at me.</td>\n",
       "      <td>ft could be you flatter yourself CoghilL It's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>Choose your targets men. That's right Watch th...</td>\n",
       "      <td>Keep steady. You're the best shots of the Twen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139407</th>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139408</th>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139409 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0       Well, I thought we'd start with pronunciation,...   \n",
       "1       Not the hacking and gagging and spitting part....   \n",
       "2       You're asking me out.  That's so cute. What's ...   \n",
       "3       No, no, it's my fault -- we didn't have a prop...   \n",
       "4          Gosh, if only we could find Kat a boyfriend...   \n",
       "...                                                   ...   \n",
       "139404    Well that one. The one who keeps looking at me.   \n",
       "139405  Choose your targets men. That's right Watch th...   \n",
       "139406  Colonel Durnford... William Vereker. I hear yo...   \n",
       "139407                           Your orders, Mr Vereker?   \n",
       "139408  I'm to take the Sikali with the main column to...   \n",
       "\n",
       "                                                   answer  \n",
       "0       Not the hacking and gagging and spitting part....  \n",
       "1       Okay... then how 'bout we try out some French ...  \n",
       "2                                              Forget it.  \n",
       "3                                                Cameron.  \n",
       "4                               Let me see what I can do.  \n",
       "...                                                   ...  \n",
       "139404  ft could be you flatter yourself CoghilL It's ...  \n",
       "139405  Keep steady. You're the best shots of the Twen...  \n",
       "139406  Good ones, yes, Mr Vereker. Gentlemen who can ...  \n",
       "139407  I'm to take the Sikali with the main column to...  \n",
       "139408  Lord Chelmsford seems to want me to stay back ...  \n",
       "\n",
       "[139409 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data[['question','answer']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28284351-bcad-4931-9ebe-1489adaaf199",
   "metadata": {},
   "source": [
    "## Check Nulls Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749441b7-1073-40ae-b64a-47e87ac91711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    0\n",
       "answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d307c1e3-aae1-48d6-bd48-aaeffed28bea",
   "metadata": {},
   "source": [
    "## check and drop Duplicated values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50112cd6-f049-4f51-95fc-938ab55b01ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbadf27-079d-464d-a652-96dd9b996586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitro\\AppData\\Local\\Temp\\ipykernel_18512\\3006716147.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b1b2bd-4bda-4443-bbc0-051c2dc66c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e786fc2d-08d5-4ff7-90b2-bb7bff2ae065",
   "metadata": {},
   "source": [
    "## Check the Number of Emojis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef1eb8f-0025-4632-9fa5-092d6ac7ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\n",
    "    \"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"\n",
    "    u\"\\U0001F300-\\U0001F5FF\"\n",
    "    u\"\\U0001F680-\\U0001F6FF\"\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "    u\"\\U00002700-\\U000027BF\"\n",
    "    u\"\\U0001F900-\\U0001F9FF\"\n",
    "    u\"\\U00002600-\\U000026FF\"\n",
    "    \"]+\",\n",
    "\n",
    "    flags=re.UNICODE,\n",
    ")\n",
    "\n",
    "def contains_emoji(text):\n",
    "    return bool(emoji_pattern.search(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a714913-495a-446c-86a7-1615cd7f6f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[\"question\"].apply(contains_emoji).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225f03ff-3a79-4dd2-932b-5cfd9ec50941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Well, I thought we'd start with pronunciation,...\n",
       "1         Not the hacking and gagging and spitting part....\n",
       "2         You're asking me out.  That's so cute. What's ...\n",
       "3         No, no, it's my fault -- we didn't have a prop...\n",
       "4            Gosh, if only we could find Kat a boyfriend...\n",
       "                                ...                        \n",
       "139404      Well that one. The one who keeps looking at me.\n",
       "139405    Choose your targets men. That's right Watch th...\n",
       "139406    Colonel Durnford... William Vereker. I hear yo...\n",
       "139407                             Your orders, Mr Vereker?\n",
       "139408    I'm to take the Sikali with the main column to...\n",
       "Name: question, Length: 138699, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce32c04-cbc2-4e26-9bc3-c87ea25908f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Not the hacking and gagging and spitting part....\n",
       "1         Okay... then how 'bout we try out some French ...\n",
       "2                                                Forget it.\n",
       "3                                                  Cameron.\n",
       "4                                 Let me see what I can do.\n",
       "                                ...                        \n",
       "139404    ft could be you flatter yourself CoghilL It's ...\n",
       "139405    Keep steady. You're the best shots of the Twen...\n",
       "139406    Good ones, yes, Mr Vereker. Gentlemen who can ...\n",
       "139407    I'm to take the Sikali with the main column to...\n",
       "139408    Lord Chelmsford seems to want me to stay back ...\n",
       "Name: answer, Length: 138699, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a323962f-298b-4696-8446-08da26c600de",
   "metadata": {},
   "source": [
    "## ChatWords & Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4159c3-541c-4d1e-a9ed-971e29e06201",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    'AFAIK':'As Far As I Know',\n",
    "    'AFK':'Away From Keyboard',\n",
    "    'ASAP':'As Soon As Possible',\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"OMG\": \"Oh My God\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"LOL\": \"Laugh Out Loud\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"GTG\": \"Got To Go\",\n",
    "    \"TTYT\": \"Talk To You Tomorrow\",\n",
    "    \"IDK\": \"I Don't Know\",\n",
    "    \"TMI\": \"Too Much Information\",\n",
    "    \"IMHO\": \"In My Humble Opinion\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"TGIF\": \"Thank God It's Friday\",\n",
    "    \"FYA\": \"For Your Action\",\n",
    "    \"ICYMI\": \"In Case You Missed It\"\n",
    "}\n",
    "\n",
    "contractions = {\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"im\":\"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"i'd\": \"i had\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"thats\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what'd\": \"what did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"'re\": \" are\",\n",
    "    \"'s\": \" is\",\n",
    "    \"'d\": \" would\",\n",
    "    \"'ll\": \" will\",\n",
    "    \"'ve\": \" have\",\n",
    "    \"n't\": \" not\",\n",
    "    \"nt\":\" not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfec691-d047-4f2d-b099-8218e56c5266",
   "metadata": {},
   "source": [
    "## Cleaning Text¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10fc8922-e0a8-40cf-91e8-8034ea2d5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    # Part_Of_Speech\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text(text, chat_words, contractions):\n",
    "\n",
    "    # @UserName:\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    # Timestamps\n",
    "    text = re.sub(r'\\d{2,4}[-/]\\d{1,2}[-/]\\d{1,2} \\d{1,2}:\\d{2}', '', text)\n",
    "    text = re.sub(r'\\d{1,2}:\\d{2}', '', text)\n",
    "\n",
    "    # HTML Tags:\n",
    "    pattern = re.compile('<.*?>')\n",
    "    text = pattern.sub(r'', text)\n",
    "\n",
    "    # Links:\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "\n",
    "    # All text to Lowercase:\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace By Contractions:\n",
    "    for k, v in contractions.items():\n",
    "        pattern = r'\\b' + re.escape(k.lower()) + r'\\b'\n",
    "        text = re.sub(pattern, v.lower(), text)\n",
    "\n",
    "    # Replace By Abbreviations:\n",
    "    for k, v in chat_words.items():\n",
    "        pattern = r'\\b' + re.escape(k.lower()) + r'\\b'\n",
    "        text = re.sub(pattern, v.lower(), text)\n",
    "\n",
    "    # Remove Punctuation:\n",
    "    for char in string.punctuation:\n",
    "        text = text.replace(char,'')\n",
    "\n",
    "    # Text Only:\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # # TextBlob\n",
    "    # blob = TextBlob(text)\n",
    "    # text = str(blob.correct())\n",
    "\n",
    "    # Tokenization:\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Lemmatization:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "\n",
    "    # Ending with \"ing\" ############################\n",
    "    # new_words = []\n",
    "    # for w in words:\n",
    "    #     if w.endswith(\"ing\") and len(w) > 4:\n",
    "    #         new_words.append(w[:-3])\n",
    "    #     else:\n",
    "    #         new_words.append(w)\n",
    "    # words = new_words\n",
    "\n",
    "    # Remove stop words:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bd6d2b0-634e-4f04-a9a3-e936404de953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Function:\n",
    "df.loc[:, \"question\"] = df[\"question\"].apply(lambda x: clean_text(x, chat_words, contractions))\n",
    "df.loc[:, \"answer\"] = df[\"answer\"].apply(lambda x: clean_text(x, chat_words, contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c53ca527-dac4-41d4-8c4b-1f977dda7db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                 well think would start pronunciation okay\n",
       " 1                          hacking gagging spit part please\n",
       " 2                                             ask cute name\n",
       " 3                                 fault proper introduction\n",
       " 4                             gosh could find kat boyfriend\n",
       "                                 ...                        \n",
       " 139404                               well one one keep look\n",
       " 139405                 choose target men right watch marker\n",
       " 139406    colonel durnford william vereker hear seek off...\n",
       " 139407                                     order mr vereker\n",
       " 139408                        take sikali main column river\n",
       " Name: question, Length: 138699, dtype: object,\n",
       " 0                         hacking gagging spit part please\n",
       " 1              okay bout try french cuisine saturday night\n",
       " 2                                                   forget\n",
       " 3                                                  cameron\n",
       " 4                                                  let see\n",
       "                                 ...                       \n",
       " 139404                       ft could flat coghill odd eye\n",
       " 139405    keep steady best shot twentyfourth bunch heathen\n",
       " 139406        good one yes mr vereker gentleman ride shoot\n",
       " 139407                       take sikali main column river\n",
       " 139408          lord chelmsford seem want stay back basuto\n",
       " Name: answer, Length: 138699, dtype: object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"question\"], df[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54ebf39d-3140-45f5-8d92-b09cdb25f7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitro\\AppData\\Local\\Temp\\ipykernel_18512\\3058211759.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"] = \"User: \" + df[\"question\"] + \"\\nAssistant: \" + df[\"answer\"]\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = \"User: \" + df[\"question\"] + \"\\nAssistant: \" + df[\"answer\"]\n",
    "texts = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fb13879-e1a6-4fa6-ac4c-e4f7093f989a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well think would start pronunciation okay</td>\n",
       "      <td>hacking gagging spit part please</td>\n",
       "      <td>User: well think would start pronunciation oka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hacking gagging spit part please</td>\n",
       "      <td>okay bout try french cuisine saturday night</td>\n",
       "      <td>User: hacking gagging spit part please\\nAssist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ask cute name</td>\n",
       "      <td>forget</td>\n",
       "      <td>User: ask cute name\\nAssistant: forget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fault proper introduction</td>\n",
       "      <td>cameron</td>\n",
       "      <td>User: fault proper introduction\\nAssistant: ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gosh could find kat boyfriend</td>\n",
       "      <td>let see</td>\n",
       "      <td>User: gosh could find kat boyfriend\\nAssistant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    question  \\\n",
       "0  well think would start pronunciation okay   \n",
       "1           hacking gagging spit part please   \n",
       "2                              ask cute name   \n",
       "3                  fault proper introduction   \n",
       "4              gosh could find kat boyfriend   \n",
       "\n",
       "                                        answer  \\\n",
       "0             hacking gagging spit part please   \n",
       "1  okay bout try french cuisine saturday night   \n",
       "2                                       forget   \n",
       "3                                      cameron   \n",
       "4                                      let see   \n",
       "\n",
       "                                                text  \n",
       "0  User: well think would start pronunciation oka...  \n",
       "1  User: hacking gagging spit part please\\nAssist...  \n",
       "2             User: ask cute name\\nAssistant: forget  \n",
       "3  User: fault proper introduction\\nAssistant: ca...  \n",
       "4  User: gosh could find kat boyfriend\\nAssistant...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d06f9-ea4b-4884-be47-f0c1de34d84b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1481e56-499e-4c0b-9480-af5f1e7d5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97db8256-7cb7-43b1-acb7-76459149ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=256):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "        for t in texts:\n",
    "            enc = tokenizer(\n",
    "                t,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            self.input_ids.append(enc[\"input_ids\"][0])\n",
    "            self.attn_masks.append(enc[\"attention_mask\"][0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attn_masks[idx],\n",
    "            \"labels\": self.input_ids[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd4a868-46b1-4349-9ffe-b0678856f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a75e6b-5017-45d1-9b1b-402d3fe28ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"openai-community/gpt2\"\n",
    ")\n",
    "\n",
    "# Match padding token\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a1c0a75-2581-4286-b66b-ab35bb0a0785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nitro\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-finetuned-chatbot\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_steps=2000,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # if GPU supports it\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13a047e2-0b54-443c-9298-791152aabad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model.save_pretrained(\"chatbot_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c23f9ac2-bec0-43b0-b703-f8713452b906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatbot_model\\\\tokenizer_config.json',\n",
       " 'chatbot_model\\\\special_tokens_map.json',\n",
       " 'chatbot_model\\\\vocab.json',\n",
       " 'chatbot_model\\\\merges.txt',\n",
       " 'chatbot_model\\\\added_tokens.json',\n",
       " 'chatbot_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"chatbot_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be198f6-168e-4309-9492-a16cd9ee3ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
